"""
Main LangGraph orchestration for document analysis workflow.
Coordinates vector/SQL retrieval, document processing, and summarisation.

NOW WITH STATE PERSISTENCE via PostgreSQL checkpointer for conversation memory.
"""

from langgraph.graph import StateGraph, START, END
import logging
import os

logger = logging.getLogger(__name__)

# Conditional import for checkpointer (only needed if use_checkpointer=True)
try:
    from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver  # type: ignore
    from psycopg_pool import AsyncConnectionPool  # type: ignore
    from psycopg import AsyncConnection  # type: ignore
    CHECKPOINTER_AVAILABLE = True
except ImportError:
    CHECKPOINTER_AVAILABLE = False
    AsyncPostgresSaver = None  # Placeholder to avoid NameError
    AsyncConnectionPool = None
    AsyncConnection = None
    logger.warning("langgraph.checkpoint.postgres not available - checkpointer features disabled")

from backend.llm.types import MainWorkflowState
from backend.llm.nodes.routing_nodes import fetch_direct_document_chunks, handle_citation_query, handle_attachment_fast, handle_navigation_action
from backend.llm.nodes.processing_nodes import process_documents
from backend.llm.nodes.summary_nodes import summarize_results
from backend.llm.nodes.formatting_nodes import format_response
# NEW: Unified agent node (replaces query_analysis_node, document_retrieval_node, chunk_retrieval_node, classify_and_prepare_query, check_cached_documents, determine_detail_level)
from backend.llm.nodes.agent_node import agent_node
from backend.llm.nodes.no_results_node import no_results_node
# LangGraph prebuilt components
from langgraph.prebuilt import ToolNode
from langgraph.types import RetryPolicy
from typing import Literal

async def create_checkpointer_for_current_loop():
    """
    Create a new checkpointer instance for the current event loop.
    Each event loop needs its own checkpointer to avoid lock conflicts.
    All checkpointers point to the same database, so persistence is shared.
    
    This allows multiple threads/event loops to use checkpointing simultaneously
    while maintaining conversation state per user_id & chat_id (thread_id).
    
    Returns:
        AsyncPostgresSaver instance or None if checkpointer unavailable
    """
    if not CHECKPOINTER_AVAILABLE:
        logger.warning("Checkpointer not available - returning None")
        return None
    
    try:
        import asyncio
        from backend.services.supabase_client_factory import get_supabase_db_url_for_checkpointer
        db_url = get_supabase_db_url_for_checkpointer()  # Use session pooler for checkpointer
        
        try:
            checkpointer = await AsyncPostgresSaver.from_conn_string(
                db_url,
                prepare_threshold=0,  # Directly disable prepared statements
                autocommit=True
            )
            logger.info("✅ Checkpointer created using from_conn_string (prepared statements disabled)")
        except (AttributeError, TypeError, Exception) as from_string_error:
            # from_conn_string might not be available or might not accept these parameters
            # Fall back to pool-based approach with connection wrapper
            logger.info(f"from_conn_string approach failed, using pool with wrapper: {from_string_error}")
            
            # Create connection string with timeout
            conn_params = db_url
            if '?' not in db_url:
                conn_params = f"{db_url}?connect_timeout=5"
            elif 'connect_timeout' not in db_url:
                conn_params = f"{db_url}&connect_timeout=5"
            
            # Create a connection factory that sets prepare_threshold=0 on each connection
            # AsyncConnection is imported at the top of the file (conditional import)
            if AsyncConnection is None:
                raise ImportError("psycopg.AsyncConnection not available")
            
            async def connection_factory(conninfo):
                """Factory that creates connections with prepare_threshold=0"""
                conn = await AsyncConnection.connect(conninfo)  # type: ignore
                conn.prepare_threshold = 0
                return conn
            
            # Create pool with connection factory
            # Note: AsyncConnectionPool might not support connection_factory directly
            # If it doesn't, we'll fall back to the basic pool and handle errors gracefully
            try:
                pool = AsyncConnectionPool(
                    conninfo=conn_params,
                    min_size=3,
                    max_size=7,
                    open=True,
                    timeout=20,
                    connection_factory=connection_factory  # Try connection factory
                )
                logger.info("✅ Checkpointer pool created with connection factory (prepared statements disabled)")
            except TypeError:
                # connection_factory not supported, use basic pool
                # We'll need to handle prepared statement errors with retry logic
                logger.warning("connection_factory not supported, using basic pool (errors will be handled gracefully)")
                pool = AsyncConnectionPool(
                    conninfo=conn_params, 
                    min_size=3,
                    max_size=7,
                    open=True,
                    timeout=20,
                )
                logger.info("✅ Checkpointer pool created (prepared statement errors will be handled gracefully)")
        
        # Create checkpointer instance for this event loop
        checkpointer = AsyncPostgresSaver(pool)
        
        # Setup tables with timeout to prevent hanging
        # Idempotent - safe to call multiple times

        try:
            # Reduced timeout to 10 seconds for faster startup - will fallback to stateless mode
            await asyncio.wait_for(checkpointer.setup(), timeout=10.0)
            logger.info("Checkpointer setup completed successfully")
        except asyncio.TimeoutError:
            logger.warning("Checkpointer setup timed out after 10 seconds - using stateless mode (this is OK)")
            return None
        except Exception as setup_error:
            error_msg = str(setup_error)

            # This is expected when tables are manually created 
            if "CREATE INDEX CONCURRENTLY cannot run inside a transaction block" in error_msg:
                logger.warning("Checkpointer setup() failed with CONCURRENTLY error - this is expected")
                logger.info("Tables already exist from migration with correct schema - continuing with checkpointer")
                # Continue with checkpointer - tables are already created and ready
            elif "does not exist" in error_msg and ("column" in error_msg or "relation" in error_msg):
                # Schema mismatch error - this should not happen after our migrations
                logger.error(f"Checkpointer setup failed with schema error: {setup_error}")
                logger.error("This indicates a schema mismatch - tables may need to be recreated")
                return None
            else:
                # For any other error, log it but still try to continue if tables exist
                # Worst case, checkpointer will fail and fall back to stateless mode
                logger.warning(f"Checkpointer setup() encountered an error: {setup_error}")
                logger.info("Assuming tables are correctly set up from migration - continuing with checkpointer")
                # Continue anyway - if tables don't work, checkpointer operations will fail and fall back to stateless
        
        logger.info("✅ Checkpointer created for current event loop (pool size: 7, prepared statements disabled)")
        return checkpointer
    except Exception as e:
        logger.error(f"Error creating checkpointer for event loop: {e}", exc_info=True)
        return None

async def build_main_graph(use_checkpointer: bool = True, checkpointer_instance=None):
    """
    Build and compile the main LangGraph orchestration with intelligent routing.

    NEW: Includes intelligent routing for performance optimization:
    - Direct document path (~2s): User attached files → fetch chunks → process → summarize
    - Simple search path (~6s): Simple query → vector search → process → summarize
    - Complex search path (~12s): Full pipeline with expansion and clarification
    
    Flow (with Routing):
    1. Route query (determines fast vs full pipeline)
    2a. Fast path: Direct document fetch → process → summarize
    2b. Simple path: Vector search → process → summarize
    2c. Complex path: Rewrite → expand → vector → clarify → process → summarize
    
    Args:
        use_checkpointer: If True, enables state persistence across conversation turns
                         via PostgreSQL. Requires SUPABASE_DB_URL environment variable.
        checkpointer_instance: Optional pre-created checkpointer instance.
                              If None and use_checkpointer=True, creates one for current event loop.
                              Use this to create checkpointers per event loop to avoid lock conflicts.

    Returns:
        Compiled LangGraph StateGraph with optional checkpointer
    """

    # Create the state graph 
    builder = StateGraph(MainWorkflowState)

    # REMOVED: check_cached_documents, classify_and_prepare_query
    # These nodes pre-processed queries and stole the agent's first thought.
    # Agent now decides its own strategy inline.
    
    # REMOVED: detect_and_extract_text, handle_general_query, transform_text, handle_follow_up_query
    # These specialized handlers are no longer needed - agent handles all query types.
    
    # REMOVED: route_query
    # Routing is now handled by simple_route() which only handles fast paths.
    # Everything else goes directly to agent.

    builder.add_node("fetch_direct_chunks", fetch_direct_document_chunks)
    """
    Fast Path Node: Direct Document Fetch
    - Fetches ALL chunks from specific document(s)
    - Bypasses vector search entirely
    - Used when user attaches files or mentions specific document
    """

    builder.add_node("handle_attachment_fast", handle_attachment_fast)
    """
    ULTRA-FAST Path Node: Attachment Fast Handler (~2s)
    - User attached file(s) and selected "fast response"
    - Uses extracted text directly - single LLM call with attachment prompt
    - Skips ALL retrieval and document search
    - ~5-10x faster than normal pipeline
    """
    
    builder.add_node("handle_citation_query", handle_citation_query)
    """
    ULTRA-FAST Path Node: Citation Query Handler (~2s)
    - User clicked on a citation and asked a question about it
    - We already have: doc_id, page, bbox, cited_text
    - Skips ALL retrieval - single LLM call with cited text + user query
    - ~5-10x faster than normal pipeline
    """
    
    # NEW: Unified Agent Node (replaces query_analysis_node, document_retrieval_node, chunk_retrieval_node)
    builder.add_node("agent", agent_node)
    """
    Unified Agent Node
    - Handles query analysis (inline)
    - Calls retrieve_documents() and retrieve_chunks() tools autonomously
    - Handles semantic retries (LLM decides when to retry)
    - Generates final answer from chunks
    - Output: messages (for tools_node), retrieved_documents, document_outputs, or final_summary
    """
    
    # Create tools for agent
    from backend.llm.tools.document_retriever_tool import create_document_retrieval_tool
    from backend.llm.tools.chunk_retriever_tool import create_chunk_retrieval_tool
    
    retrieval_tools = [
        create_document_retrieval_tool(),
        create_chunk_retrieval_tool(),
    ]
    
    # Add tools node with retry policy for execution failures
    builder.add_node(
        "tools",
        ToolNode(tools=retrieval_tools),
        retry_policy=RetryPolicy(
            max_attempts=3,
            retry_on=(ConnectionError, TimeoutError, Exception)
        )
    )
    """
    Tools Node
    - Executes tool calls from agent (retrieve_documents, retrieve_chunks)
    - Handles execution failures (timeouts, DB errors) via RetryPolicy
    - Returns ToolMessages to agent for processing
    - Does NOT handle semantic retries (that's agent's job)
    """
    
    builder.add_node("no_results_node", no_results_node)
    """
    NEW: No Results Node (Shared Failure Handler)
    - Generates helpful failure messages when retries are exhausted
    - Explains what was searched, suggests rephrasing
    - Output: final_summary with helpful failure message
    """
    
    builder.add_node("handle_navigation_action", handle_navigation_action)
    """
    INSTANT Path Node: Navigation Action Handler (~0.1s)
    - User wants to navigate to a property on the map
    - Examples: "take me to highlands", "show me on the map"
    - Skips ALL document retrieval - directly emits agent actions
    - Frontend handles map opening and pin selection
    """

    # EXISTING NODES (Full Pipeline)
    # REMOVED: rewrite_query, expand_query, query_vector_documents, clarify_relevant_docs
    # These are replaced by agent tools in summarize_results node (retrieve_documents + retrieve_chunks)

    # REMOVED: determine_detail_level
    # Agent decides detail level based on query context.

    builder.add_node("process_documents", process_documents)
    """
    Node 5: Process Documents (parallel subgraph invocations)
    - Input: relevant_documents, user_query, conversation_history
    - For each unique document:
        - Invokes document_qa_subgraph
        - LLM extracts relevant information from document
    - Output: document_outputs (list of per-document analyses)
    - Supports simple_mode for faster stubbed responses
    """

    builder.add_node("summarize_results", summarize_results)
    """
    Node 6: Summarize
    - Input: document_outputs, user_query, conversation_history
    - LLM creates unified summary from all document analyses
    - References previous conversation for follow-up questions
    - Uses natural language (addresses and filenames, not IDs)
    - Output: final_summary, updated conversation_history
    """

    builder.add_node("format_response", format_response)
    """
    Node 7: Format Response
    - Input: final_summary (raw LLM response)
    - Formats and structures the response for better readability
    - Ensures logical organization, consistent formatting, and completeness
    - Output: formatted final_summary
    """
    
    # ROUTING LOGIC FUNCTIONS
    # REMOVED: should_route() and should_use_cached_documents()
    # These old routing functions are replaced by simple_route() which handles fast paths only.
    # Everything else goes directly to the agent.

    # BUILD GRAPH EDGES - SIMPLIFIED ROUTING
    # START → simple router (only handles fast paths, everything else → agent)
    def simple_route(state: MainWorkflowState) -> Literal["handle_navigation_action", "handle_citation_query", "handle_attachment_fast", "fetch_direct_chunks", "agent"]:
        """
        Simplified routing from START.
        
        Fast paths (skip agent):
        - Navigation actions
        - Citation queries
        - Attachment fast mode
        - Direct document access (document_ids provided)
        
        Everything else → agent (agent decides its own strategy)
        """
        # Check for fast paths
        query_type = state.get("query_type")
        citation_context = state.get("citation_context")
        attached_document = state.get("attached_document")
        fast_mode = state.get("fast_mode", False)
        document_ids = state.get("document_ids")
        
        # Navigation action
        if query_type == "navigation_action":
            logger.info("[GRAPH] Fast path: navigation_action")
            return "handle_navigation_action"
        
        # Citation query (citation click)
        if citation_context or query_type == "citation_query":
            logger.info("[GRAPH] Fast path: citation_query")
            return "handle_citation_query"
        
        # Attachment fast mode
        if attached_document and fast_mode:
            logger.info("[GRAPH] Fast path: attachment_fast")
            return "handle_attachment_fast"
        
        # Direct document access (document_ids provided)
        if document_ids:
            logger.info(f"[GRAPH] Fast path: direct_document (doc_ids={document_ids})")
            return "fetch_direct_chunks"
        
        # Everything else goes to agent
        logger.info("[GRAPH] Routing to agent (agent-driven retrieval)")
        return "agent"
    
    builder.add_conditional_edges(
        START,
        simple_route,
        {
            "navigation_action": "handle_navigation_action",
            "citation_query": "handle_citation_query",
            "handle_attachment_fast": "handle_attachment_fast",
            "fetch_direct_chunks": "fetch_direct_chunks",
            "agent": "agent"
        }
    )
    logger.debug("START -> [navigation_action|citation_query|attachment_fast|direct_chunks|agent]")
    
    # NAVIGATION PATH: handle → format (INSTANT, skips ALL retrieval - just emits agent actions)
    builder.add_edge("handle_navigation_action", "format_response")
    logger.debug("Edge: handle_navigation_action -> format_response (INSTANT)")
    
    # ATTACHMENT FAST PATH: handle → format (ULTRA-FAST ~2s, skips ALL retrieval + processing)
    builder.add_edge("handle_attachment_fast", "format_response")
    logger.debug("Edge: handle_attachment_fast -> format_response (ULTRA-FAST)")
    
    # CITATION PATH: handle → format (ULTRA-FAST ~2s, skips ALL retrieval + processing)
    builder.add_edge("handle_citation_query", "format_response")
    logger.debug("Edge: handle_citation_query -> format_response (ULTRA-FAST)")

    # DIRECT PATH: fetch → process → summarize (FASTEST ~2s)
    builder.add_edge("fetch_direct_chunks", "process_documents")
    logger.debug("Edge: fetch_direct_chunks -> process_documents")

    # Helper node to extract final answer from messages for API response
    def extract_final_answer(state: MainWorkflowState) -> MainWorkflowState:
        """
        Extract final answer from agent's last message.
        
        This is NOT manual extraction of tool results - it's just formatting
        the final output for the API response.
        """
        messages = state.get("messages", [])
        
        if messages:
            last_message = messages[-1]
            if hasattr(last_message, 'content') and last_message.content:
                logger.info(f"[EXTRACT_FINAL] Extracted final answer ({len(last_message.content)} chars)")
                return {"final_summary": last_message.content}
        
        logger.warning("[EXTRACT_FINAL] No final answer found in messages")
        return {"final_summary": "I apologize, but I couldn't generate a response."}
    
    builder.add_node("extract_final_answer", extract_final_answer)
    
    # NEW: Agent-driven retrieval path (SIMPLIFIED)
    # Agent → tools → agent (loop) → extract_final_answer → END
    def should_continue(state: MainWorkflowState) -> Literal["tools", "extract_final_answer"]:
        """
        Determine next step after agent node.
        
        SIMPLIFIED ROUTING:
        - If agent made tool calls → execute them
        - Else → extract final answer from messages
        
        The agent sees ToolMessages naturally and decides when it's done.
        No manual extraction of tool results. No pre-processing.
        """
        messages = state.get("messages", [])
        
        if not messages:
            logger.warning("[GRAPH] No messages in state, routing to extract_final_answer")
            return "extract_final_answer"
        
        # Check last message for tool calls
        last_message = messages[-1]
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            logger.debug(f"[GRAPH] Agent made {len(last_message.tool_calls)} tool call(s), routing to tools")
            return "tools"
        
        # No tool calls - agent generated final answer
        logger.debug("[GRAPH] Agent finished (no tool calls), routing to extract_final_answer")
        return "extract_final_answer"
    
    builder.add_conditional_edges(
        "agent",
        should_continue,
        {
            "tools": "tools",
            "extract_final_answer": "extract_final_answer"
        }
    )
    logger.debug("Conditional: agent -> [tools|extract_final_answer]")
    
    # Tools → Agent (loop back)
    builder.add_edge("tools", "agent")
    logger.debug("Edge: tools -> agent (loop back)")
    
    # Extract final answer → END
    builder.add_edge("extract_final_answer", END)
    logger.debug("Edge: extract_final_answer -> END")
    
    # Format response → END (for fast paths that go through format_response)
    builder.add_edge("format_response", END)
    logger.debug("Edge: format_response -> END")

    # ALL PATHS CONVERGE HERE
    builder.add_edge("process_documents", "summarize_results")
    logger.debug("Edge: process_documents -> summarize_results")

    # Conditional edge from summarize_results: route to no_results_node if no documents
    def should_route_to_no_results(state: MainWorkflowState) -> Literal["no_results_node", "END"]:
        """Route to no_results_node if final_summary is None (no documents found)."""
        final_summary = state.get("final_summary")
        doc_outputs = state.get("document_outputs", []) or []
        
        if final_summary is None or (not doc_outputs and final_summary is None):
            logger.debug("[GRAPH] summarize_results returned None - routing to no_results_node")
            return "no_results_node"
        else:
            logger.debug(f"[GRAPH] summarize_results has summary ({len(final_summary) if final_summary else 0} chars) - routing to END")
            return "END"
    
    builder.add_conditional_edges(
        "summarize_results",
        should_route_to_no_results,
        {
            "no_results_node": "no_results_node",  # No documents - go to failure handler
            "END": END  # Success - end graph
        }
    )
    logger.debug("Conditional: summarize_results -> [no_results_node|END]")
    
    # REMOVED: Edges for removed nodes (handle_general_query, detect_and_extract_text, transform_text, handle_follow_up_query)

    # Add checkpointer setup
    checkpointer = None 

    if use_checkpointer:
        # Use provided checkpointer instance, or create one for current event loop
        if checkpointer_instance:
            checkpointer = checkpointer_instance
            logger.info("Using provided checkpointer instance")
        else:
            # Create checkpointer for current event loop
            checkpointer = await create_checkpointer_for_current_loop()
            if not checkpointer:
                logger.warning("Failed to create checkpointer - using stateless mode")
                main_graph = builder.compile()
                return main_graph, None

        # Compile with checkpointer (subgraphs will inherit it automatically)
        main_graph = builder.compile(checkpointer=checkpointer)
        logger.info("Graph compiled with checkpointer")

        return main_graph, checkpointer

    else:
        main_graph = builder.compile()
        return main_graph, checkpointer

# Global graph and checkpointer instances (initialized on app startup)
main_graph = None 
checkpointer = None

async def initialize_graph():
    """Initialize LangGraph on app startup - call this once before handling requests"""
    global main_graph, checkpointer
    main_graph, checkpointer = await build_main_graph(use_checkpointer=True)
    logger.info("✅ LangGraph initialized with checkpointer")





